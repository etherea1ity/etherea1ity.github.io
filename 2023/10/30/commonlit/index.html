<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>commonlit competition review | Jerryの魔法小屋</title><meta name="author" content="Jerry Jiang"><meta name="copyright" content="Jerry Jiang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CommonLit - Evaluate Student Summaries (with detailed code)INTRODUCTION OF THE COMPETITIONCompetition WebsiteCommonlit DescriptionThe goal of this competition is to assess the quality of summaries wri">
<meta property="og:type" content="article">
<meta property="og:title" content="commonlit competition review">
<meta property="og:url" content="http://example.com/2023/10/30/commonlit/index.html">
<meta property="og:site_name" content="Jerryの魔法小屋">
<meta property="og:description" content="CommonLit - Evaluate Student Summaries (with detailed code)INTRODUCTION OF THE COMPETITIONCompetition WebsiteCommonlit DescriptionThe goal of this competition is to assess the quality of summaries wri">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/commonlit.png">
<meta property="article:published_time" content="2023-10-30T13:53:55.000Z">
<meta property="article:modified_time" content="2024-03-12T16:18:17.932Z">
<meta property="article:author" content="Jerry Jiang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/commonlit.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/10/30/commonlit/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'commonlit competition review',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-13 00:18:17'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><script src="/live2d-widget/autoload.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/commonlit.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Jerryの魔法小屋"><span class="site-name">Jerryの魔法小屋</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">commonlit competition review</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-30T13:53:55.000Z" title="发表于 2023-10-30 21:53:55">2023-10-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-12T16:18:17.932Z" title="更新于 2024-03-13 00:18:17">2024-03-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/machine-learning/">machine learning</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/machine-learning/kaggle/">kaggle</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="commonlit competition review"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="CommonLit-Evaluate-Student-Summaries-with-detailed-code"><a href="#CommonLit-Evaluate-Student-Summaries-with-detailed-code" class="headerlink" title="CommonLit - Evaluate Student Summaries (with detailed code)"></a>CommonLit - Evaluate Student Summaries (with detailed code)</h1><h2 id="INTRODUCTION-OF-THE-COMPETITION"><a href="#INTRODUCTION-OF-THE-COMPETITION" class="headerlink" title="INTRODUCTION OF THE COMPETITION"></a>INTRODUCTION OF THE COMPETITION</h2><h3 id="Competition-Website"><a href="#Competition-Website" class="headerlink" title="Competition Website"></a>Competition Website</h3><p><a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview">Commonlit</a></p>
<h3 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h3><p>The goal of this competition is to assess the quality of summaries written by students in grades 3-12. We need to build a model that evaluates how well a student represents the main idea and details of a source text, as well as the clarity, precision, and fluency of the language used in the summary.</p>
<h3 id="Evaluation-Metric"><a href="#Evaluation-Metric" class="headerlink" title="Evaluation Metric"></a>Evaluation Metric</h3><p>Submissions are scored using MCRMSE, mean column wise root mean squared error: <script type="math/tex">MCRMSE = {1\over N_t}\sum_{j=1}^{N_t}({1 \over {n}} \sum_{i=1}^n(y_{ij}-\hat y_{ij}))^2</script></p>
<p>where $N_t$ is the number of scored ground truth target columns, and $y$ and $\hat y$ are the actual and predicted values, respectively.</p>
<h3 id="Brief-Process"><a href="#Brief-Process" class="headerlink" title="Brief Process"></a>Brief Process</h3><ol>
<li>Eda </li>
<li>feature engineering</li>
<li>Multiple models buildings(deberta，lightgbm,  Catboost,  xgboost) </li>
<li>optimization, ensemble</li>
</ol>
<h2 id="DETAILED-PROCESS"><a href="#DETAILED-PROCESS" class="headerlink" title="DETAILED PROCESS"></a>DETAILED PROCESS</h2><h3 id="EDA-Exploratory-Data-Analysis"><a href="#EDA-Exploratory-Data-Analysis" class="headerlink" title="EDA-Exploratory Data Analysis"></a>EDA-Exploratory Data Analysis</h3><p>We used numpy,  pandas, matplotlib.pyplot and seaborn to analyze data</p>
<h4 id="basic-information-of-the-data"><a href="#basic-information-of-the-data" class="headerlink" title="basic information of the data"></a>basic information of the data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read files, use pd.read_csv()</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prompts train: <span class="subst">&#123;prompts_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prompts test: <span class="subst">&#123;prompts_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Summaries train: <span class="subst">&#123;summaries_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Summaries test: <span class="subst">&#123;summaries_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompts</span></span><br><span class="line">pd.options.display.max_colwidth = <span class="number">1000</span> <span class="comment"># display the whole text of prompts</span></span><br><span class="line">prompts_train.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Summaries</span></span><br><span class="line">summaries_train.head()</span><br><span class="line"><span class="comment">#How many students?</span></span><br><span class="line"><span class="built_in">len</span>(summaries_train[<span class="string">&#x27;student_id&#x27;</span>].unique())</span><br></pre></td></tr></table></figure>
<p>We had the length of each files and some detailed information like prompt ID and student’s scores of content and wording separately.</p>
<h4 id="Exploratory-of-Prompt-ID"><a href="#Exploratory-of-Prompt-ID" class="headerlink" title="Exploratory of Prompt ID"></a>Exploratory of Prompt ID</h4><p>First of all, we used plt to draw a bar chart of the distribution of each Prompt ID.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Distribution of each Prompt ID</span></span><br><span class="line"><span class="comment">#We can observe unequal distribution of prompt examples.</span></span><br><span class="line">plt.title(<span class="string">&quot;Distribution of Prompt ID&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Prompt ID&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Count of summaries for particualr Prompt ID&quot;</span>)</span><br><span class="line">summaries_train.prompt_id.value_counts().plot(kind=<span class="string">&quot;bar&quot;</span>)</span><br><span class="line"><span class="comment"># There are 4 diffrent prompts for students to deal with:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># On Tragedy</span></span><br><span class="line"><span class="comment"># Egyptian Social Structure</span></span><br><span class="line"><span class="comment"># The Third Wave</span></span><br><span class="line"><span class="comment"># Excerpt from The Jungle</span></span><br></pre></td></tr></table></figure>
<p>We got the graph below, and we could observe unequal distribution of prompt examples.</p>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/Screenshot 2024-03-12 225052.png" alt=""></p>
<p>We’d like to analyze Prompt ID more precisely.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">prompts_df = pd.read_csv(<span class="string">&quot;/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv&quot;</span>)</span><br><span class="line">prompts_mapping = (prompts_df.set_index([<span class="string">&quot;prompt_id&quot;</span>])[<span class="string">&quot;prompt_title&quot;</span>]).to_dict()</span><br><span class="line">prompts_df.set_index(<span class="string">&quot;prompt_id&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">summaries_df = pd.read_csv(<span class="string">&quot;/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv&quot;</span>)</span><br><span class="line">summaries_df[<span class="string">&quot;prompt_title&quot;</span>] = summaries_df[<span class="string">&quot;prompt_id&quot;</span>].<span class="built_in">map</span>(prompts_mapping)</span><br><span class="line"></span><br><span class="line"><span class="comment"># bar chart with precise percentages of each column and count</span></span><br><span class="line">total=<span class="built_in">len</span>(summaries_df)</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>, figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">sns.countplot(x=summaries_df[<span class="string">&quot;prompt_title&quot;</span>], palette=palette, ax=ax)</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> ax.patches:</span><br><span class="line">    percentage = <span class="string">&#x27;&#123;:.2f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * p.get_height()/total)</span><br><span class="line">    x = p.get_x() + p.get_width()/<span class="number">2</span></span><br><span class="line">    y = p.get_height() * <span class="number">1.01</span></span><br><span class="line">    ax.annotate(percentage, (x, y), ha=<span class="string">&#x27;center&#x27;</span>, fontsize=<span class="number">12</span>)</span><br></pre></td></tr></table></figure>
<p>It seemed better now.</p>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/output.png" alt=""></p>
<p>And some other details.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Range of content score:</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(summaries_train.content), <span class="built_in">min</span>(summaries_train.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output: 3.90032610436019 -1.72985945253881</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Range of wording score:¶</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(summaries_train.wording), <span class="built_in">min</span>(summaries_train.wording))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output: 4.3106931513921 -1.96261379376134</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.histplot(data=summaries_train, x=<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.histplot(data=summaries_train, x=<span class="string">&#x27;wording&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="Wordcloud"><a href="#Wordcloud" class="headerlink" title="Wordcloud"></a>Wordcloud</h4><p>We used a common python words analyzer wordcloud to generate a image of words which sizes were based on the frequency of their occurence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Prompt Wordcloud</span></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">wordcloud</span>(<span class="params">text, title</span>):</span><br><span class="line">    <span class="comment"># Generate a word cloud image</span></span><br><span class="line">    wordcloud = WordCloud().generate(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># take relative word frequencies into account, lower max_font_size</span></span><br><span class="line">    wordcloud = WordCloud(background_color=<span class="string">&quot;white&quot;</span>,max_words=<span class="built_in">len</span>(text),max_font_size=<span class="number">40</span>, relative_scaling=<span class="number">.5</span>).generate(text)</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.imshow(wordcloud)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p> Texts from prompts</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># join the text from training</span></span><br><span class="line">prompt_content_text = <span class="string">&#x27; &#x27;</span>.join(prompts_train[<span class="string">&#x27;prompt_text&#x27;</span>])</span><br><span class="line"></span><br><span class="line">wordcloud(prompt_content_text, <span class="string">&quot;Texts from prompts&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/outputcloud1.png" alt=""></p>
<p>Texts from Summaries</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Word cloud of content</span></span><br><span class="line">content_text = <span class="string">&#x27; &#x27;</span>.join(summaries_train[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line"></span><br><span class="line">wordcloud(content_text, <span class="string">&quot;Summaries&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/outputcloud2.png" alt=""></p>
<p>We could observe similar words in prompts and summaries as expected such as people, bad, noble etc.</p>
<p>We used wordcloud again to find common words between prompt and summary.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># combine all words from the prompt text</span></span><br><span class="line">prompt_text = <span class="string">&#x27;&#x27;</span>.join(prompts_train.prompt_text).lower().split(<span class="string">&quot; &quot;</span>) </span><br><span class="line">prompt_summary_text = <span class="string">&#x27;&#x27;</span>.join(summaries_train.text).lower().split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use intersection to find all the common words between prompt and summary</span></span><br><span class="line">common_words = <span class="built_in">set</span>(prompt_summary_text).intersection(<span class="built_in">set</span>(prompt_text)) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of words in prompt: <span class="subst">&#123;<span class="built_in">len</span>(prompt_text)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of words in summary: <span class="subst">&#123;<span class="built_in">len</span>(prompt_summary_text)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of common words in prompt and summary: <span class="subst">&#123;<span class="built_in">len</span>(common_words)&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">wordcloud(<span class="string">&#x27; &#x27;</span>.join(common_words), <span class="string">&quot;Common words in prompts &amp; summaries&quot;</span>)</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># Number of words in prompt: 2714</span></span><br><span class="line"><span class="comment"># Number of words in summary: 538491</span></span><br><span class="line"><span class="comment"># Number of common words in prompt and summary: 1062</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/outputcloud1.png" alt=""></p>
<h4 id="Exploration-of-correlation-of-scores-of-wording-and-content"><a href="#Exploration-of-correlation-of-scores-of-wording-and-content" class="headerlink" title="Exploration of correlation of scores of wording and content."></a>Exploration of correlation of scores of wording and content.</h4><p>Firstly, we use box plot and violin plot that we had studied in probability statistics to explore the correlation of wording and content score.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tmp_content = summaries_df[[<span class="string">&quot;content&quot;</span>, <span class="string">&quot;prompt_title&quot;</span>]]</span><br><span class="line">tmp_content.loc[:, <span class="string">&quot;type&quot;</span>] = <span class="string">&quot;content&quot;</span></span><br><span class="line">tmp_content.rename(columns=&#123;<span class="string">&quot;content&quot;</span>: <span class="string">&quot;value&quot;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">tmp_wording = summaries_df[[<span class="string">&quot;wording&quot;</span>, <span class="string">&quot;prompt_title&quot;</span>]]</span><br><span class="line">tmp_wording.loc[:, <span class="string">&quot;type&quot;</span>] = <span class="string">&quot;wording&quot;</span></span><br><span class="line">tmp_wording.rename(columns=&#123;<span class="string">&quot;wording&quot;</span>: <span class="string">&quot;value&quot;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">tmp = pd.concat([tmp_content, tmp_wording])</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>,<span class="number">1</span>, figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">sns.boxplot(data=tmp, x=<span class="string">&quot;prompt_title&quot;</span>, y=<span class="string">&quot;value&quot;</span>, hue=<span class="string">&quot;type&quot;</span>, palette=palette, ax=axs[<span class="number">0</span>])</span><br><span class="line">sns.violinplot(data=tmp, x=<span class="string">&quot;prompt_title&quot;</span>, y=<span class="string">&quot;value&quot;</span>, hue=<span class="string">&quot;type&quot;</span>, palette=palette, ax=axs[<span class="number">1</span>])</span><br><span class="line">axs[<span class="number">0</span>].legend(loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].legend(loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/kaggleboxviolin.png" alt=""></p>
<p>And we used seaborn to explore our data, which was a very helpful tool for making statistical graphics.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g = sns.jointplot(summaries_df, x=<span class="string">&quot;content&quot;</span>, y=<span class="string">&quot;wording&quot;</span>, hue=<span class="string">&quot;prompt_title&quot;</span>, </span><br><span class="line">                  s=<span class="number">5</span>, marginal_kws=<span class="built_in">dict</span>(fill=<span class="literal">False</span>), palette=palette)</span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/kacoseaborn.png" alt=""></p>
<p>And now we found that: </p>
<ol>
<li>There had a strong correlation between the content score and wording score.</li>
<li>Most of the students received score between -1 and 2.</li>
<li>For prompts “Egyptian Social Structure” and “On Tragedy”, there was a significant gap between the best content and wording score.</li>
</ol>
<h4 id="Word-statistics-Rouge-Score"><a href="#Word-statistics-Rouge-Score" class="headerlink" title="Word statistics (Rouge Score)"></a>Word statistics (Rouge Score)</h4><p>Firstly, we calculate the number of words and sentences in each summaries. From our perspective, we assumed that summaries written by good students tended to be longer. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># number of sentences</span></span><br><span class="line">summaries_df[<span class="string">&quot;n_sentences&quot;</span>] = summaries_df[<span class="string">&quot;text&quot;</span>].apply(<span class="keyword">lambda</span> text: <span class="built_in">len</span>(text.split(<span class="string">&quot;.&quot;</span>)))</span><br><span class="line"><span class="comment"># number of words</span></span><br><span class="line">summaries_df[<span class="string">&quot;n_words&quot;</span>] = summaries_df[<span class="string">&quot;text&quot;</span>].apply(<span class="keyword">lambda</span> text: <span class="built_in">len</span>(text.split()))</span><br><span class="line"><span class="comment"># average words per sentence</span></span><br><span class="line">summaries_df[<span class="string">&quot;av_words_per_sentence&quot;</span>] = <span class="built_in">round</span>(summaries_df[<span class="string">&quot;n_words&quot;</span>] / summaries_df[<span class="string">&quot;n_sentences&quot;</span>], <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>We downloaded stopwords (for example, your me his etc.) from NLTK (Natural Language Toolkit) library. We assumed that the stopwords cannot be a evaluation criteria for the question.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_stop_words</span>(<span class="params">text</span>):</span><br><span class="line">    filtered_words = [word <span class="keyword">for</span> word <span class="keyword">in</span> text.split() <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">&#x27;english&#x27;</span>)]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(filtered_words).lower()</span><br><span class="line">   </span><br><span class="line">prompts_df[<span class="string">&quot;prompt_filtered&quot;</span>] = prompts_df[<span class="string">&quot;prompt_text&quot;</span>].apply(<span class="keyword">lambda</span> text: remove_stop_words(text))</span><br><span class="line">summaries_df[<span class="string">&quot;text_filtered&quot;</span>] = summaries_df[<span class="string">&quot;text&quot;</span>].apply(<span class="keyword">lambda</span> text: remove_stop_words(text))</span><br></pre></td></tr></table></figure>
<p>We removed stopwords from prompts and summaries, then we used rouge to evaluate each summaries. </p>
<p>We know that rouge score can help us evaluate how well our NLP models perform on various task such as summarization, translation or dialogue generation. We use it to evaluate the summaries that written by students.</p>
<p>We used the original text as reference, and summaries written by students as hypothesis.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index, data <span class="keyword">in</span> summaries_df.iterrows():</span><br><span class="line">    reference = prompts_df.loc[data[<span class="string">&quot;prompt_id&quot;</span>], <span class="string">&quot;prompt_filtered&quot;</span>]</span><br><span class="line">    hypothesis = data[<span class="string">&quot;text_filtered&quot;</span>]</span><br><span class="line">    scores = Rouge().get_scores(hypothesis, reference)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> metric_name, values <span class="keyword">in</span> scores.items():</span><br><span class="line">        <span class="keyword">for</span> value_name, score <span class="keyword">in</span> values.items():</span><br><span class="line">            col_name = metric_name + <span class="string">&quot;-&quot;</span> + value_name</span><br><span class="line">            summaries_df.loc[index, col_name] = score</span><br><span class="line">summaries_df.drop([<span class="string">&#x27;student_id&#x27;</span>, <span class="string">&#x27;prompt_id&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&quot;text_filtered&quot;</span>], axis=<span class="number">1</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p>And we got a bunch of data.</p>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/rougescorescom.png" alt=""></p>
<p>What does each element means? </p>
<p>r: recall, p: precise, f: 2*(recall*precision) / (recall + precision), f1-scores is the score that calculate in 1-grams.</p>
<p>In order to more intuitively demonstrate the correlation between various items, we drew a correlation matrix.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">columns = <span class="built_in">list</span>(summaries_df.select_dtypes([<span class="string">&#x27;number&#x27;</span>]).columns)</span><br><span class="line">tmp_df = summaries_df[columns]</span><br><span class="line"></span><br><span class="line">f = plt.figure(figsize=(<span class="number">12</span>, <span class="number">14</span>))</span><br><span class="line"><span class="comment"># Red and Purple correlation matrix</span></span><br><span class="line">plt.matshow(tmp_df.corr(), fignum=f.number, cmap=<span class="string">&quot;RdPu&quot;</span>)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(columns)), columns, fontsize=<span class="number">14</span>, rotation=<span class="number">85</span>)</span><br><span class="line">plt.yticks(<span class="built_in">range</span>(<span class="built_in">len</span>(columns)), columns, fontsize=<span class="number">14</span>)</span><br><span class="line"><span class="comment"># colorbar represent correlation</span></span><br><span class="line">cb = plt.colorbar()</span><br><span class="line">cb.ax.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Correlation matrix&quot;</span>, fontsize=<span class="number">16</span>);</span><br></pre></td></tr></table></figure>
<p><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/cocorrelationma.png" alt=""></p>
<p>The correlation matrix indicates that number of words and number of sentences in summary is strongly correllated to the overall score. In addition to that, f1-rogue metric is strongly correlated with content score (correlation coefficient &gt; 0.6) and not-so-strongly with wording score (correlation coefficient &gt; 0.3).</p>
<p>Conclusion: Statistics concerning student summaries together with rogue metric evaluation (all in form of tabular data) might be used for predicting student score. </p>
<p>Lastly, we printed the correlation coefficient between length of text and wording and content score.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">summaries_df[<span class="string">&#x27;text_len&#x27;</span>] = summaries_df[<span class="string">&#x27;text&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x))</span><br><span class="line">summaries_df[[<span class="string">&#x27;text_len&#x27;</span>, <span class="string">&#x27;content&#x27;</span>, <span class="string">&#x27;wording&#x27;</span>]].corr()</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># text_len	content	wording</span></span><br><span class="line"><span class="comment"># text_len	1.000000	0.797244	0.540138</span></span><br><span class="line"><span class="comment"># content	0.797244	1.000000	0.751380</span></span><br><span class="line"><span class="comment"># wording	0.540138	0.751380	1.000000</span></span><br></pre></td></tr></table></figure>
<h3 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h3><h3 id="Machine-Learning-Models"><a href="#Machine-Learning-Models" class="headerlink" title="Machine Learning Models"></a>Machine Learning Models</h3><h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><h2 id="Final-Score"><a href="#Final-Score" class="headerlink" title="Final Score"></a>Final Score</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Jerry Jiang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/10/30/commonlit/">http://example.com/2023/10/30/commonlit/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Jerryの魔法小屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/commonlit.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/09/%E8%AE%A1%E7%BD%91/%E8%AE%A1%E7%BD%91%E7%AC%AC9%E7%AB%A0/" title="计网第九章"><img class="cover" src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">计网第九章</div></div></a></div><div class="next-post pull-right"><a href="/2023/10/30/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA%E7%AC%AC2%E7%AB%A0/" title="第二章关系数据库"><img class="cover" src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/DATABASECARTOON.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">第二章关系数据库</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jerry Jiang</div><div class="author-info__description">赞美太阳！</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/etherea1ity"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/etherea1ity" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:jsj31415926@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的小屋！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CommonLit-Evaluate-Student-Summaries-with-detailed-code"><span class="toc-number">1.</span> <span class="toc-text">CommonLit - Evaluate Student Summaries (with detailed code)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#INTRODUCTION-OF-THE-COMPETITION"><span class="toc-number">1.1.</span> <span class="toc-text">INTRODUCTION OF THE COMPETITION</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Competition-Website"><span class="toc-number">1.1.1.</span> <span class="toc-text">Competition Website</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Description"><span class="toc-number">1.1.2.</span> <span class="toc-text">Description</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation-Metric"><span class="toc-number">1.1.3.</span> <span class="toc-text">Evaluation Metric</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Brief-Process"><span class="toc-number">1.1.4.</span> <span class="toc-text">Brief Process</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DETAILED-PROCESS"><span class="toc-number">1.2.</span> <span class="toc-text">DETAILED PROCESS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#EDA-Exploratory-Data-Analysis"><span class="toc-number">1.2.1.</span> <span class="toc-text">EDA-Exploratory Data Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#basic-information-of-the-data"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">basic information of the data</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Exploratory-of-Prompt-ID"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">Exploratory of Prompt ID</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Wordcloud"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">Wordcloud</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Exploration-of-correlation-of-scores-of-wording-and-content"><span class="toc-number">1.2.1.4.</span> <span class="toc-text">Exploration of correlation of scores of wording and content.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Word-statistics-Rouge-Score"><span class="toc-number">1.2.1.5.</span> <span class="toc-text">Word statistics (Rouge Score)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-Engineering"><span class="toc-number">1.2.2.</span> <span class="toc-text">Feature Engineering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Machine-Learning-Models"><span class="toc-number">1.2.3.</span> <span class="toc-text">Machine Learning Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ensemble"><span class="toc-number">1.2.4.</span> <span class="toc-text">Ensemble</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Final-Score"><span class="toc-number">1.3.</span> <span class="toc-text">Final Score</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/01/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC5%E7%AB%A0/" title="操作系统第5章"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统第5章"/></a><div class="content"><a class="title" href="/2024/01/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC5%E7%AB%A0/" title="操作系统第5章">操作系统第5章</a><time datetime="2024-01-15T08:45:20.221Z" title="发表于 2024-01-15 16:45:20">2024-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC1%E7%AB%A0/" title="操作系统第1章"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统第1章"/></a><div class="content"><a class="title" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC1%E7%AB%A0/" title="操作系统第1章">操作系统第1章</a><time datetime="2023-11-10T06:07:21.000Z" title="发表于 2023-11-10 14:07:21">2023-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC4%E7%AB%A0/" title="操作系统第4章"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统第4章"/></a><div class="content"><a class="title" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC4%E7%AB%A0/" title="操作系统第4章">操作系统第4章</a><time datetime="2023-11-10T06:07:21.000Z" title="发表于 2023-11-10 14:07:21">2023-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC2%E7%AB%A0/" title="操作系统第2章"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统第2章"/></a><div class="content"><a class="title" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC2%E7%AB%A0/" title="操作系统第2章">操作系统第2章</a><time datetime="2023-11-10T06:07:21.000Z" title="发表于 2023-11-10 14:07:21">2023-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC3%E7%AB%A0/" title="操作系统第3章"><img src="https://imageurlbed.oss-cn-shenzhen.aliyuncs.com/img/mountains-7750722_1920.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统第3章"/></a><div class="content"><a class="title" href="/2023/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC3%E7%AB%A0/" title="操作系统第3章">操作系统第3章</a><time datetime="2023-11-10T06:07:21.000Z" title="发表于 2023-11-10 14:07:21">2023-11-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Jerry Jiang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>